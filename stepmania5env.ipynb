{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow\n",
    "# %pip install gym\n",
    "# %pip install keras\n",
    "# %pip install keras-rl2\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from matplotlib import pyplot as plt\n",
    "from mss import mss\n",
    "import numpy as np \n",
    "import time\n",
    "import pydirectinput\n",
    "import pygetwindow\n",
    "import cv2\n",
    "import win32gui\n",
    "import gym as gym\n",
    "from image_analysis.take_screenshot import Screenshot\n",
    "from input_sending.input_sending import SendInput \n",
    "from pattern_recognition.pattern_recog import RecognizePattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepManiaEnv(Env):\n",
    "    \n",
    "    # Setup\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(5)\n",
    "\n",
    "        # Observation Array\n",
    "        self.observation_space = Box(\n",
    "            low=0, \n",
    "            high=255, \n",
    "            shape=(1, 135, 100),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        \n",
    "        # Define extraction parameters for the game\n",
    "        self.screenshot_helper = Screenshot()\n",
    "        self.input_sending_helper = SendInput()\n",
    "        self.pattern_recog_helper = RecognizePattern()\n",
    "        self.capture = mss()\n",
    "        self.steps = 0\n",
    "        self.previous_reward = 0\n",
    "        self.window_location = {'top': 35, 'left': 10, 'width': 410, 'height': 230}\n",
    "        self.game_location = {'top': 15, 'left': 20, 'width': 100, 'height': 185}\n",
    "        self.score_location = {'top': 215, 'left': 280, 'width': 100, 'height': 25}\n",
    "        self.done_location = {'top': 0, 'left': 0, 'width': 90, 'height':25}\n",
    "        self.cur_held_buttons = {'a': False, 'd': False, 'w': False, 's': False}\n",
    "        \n",
    "        # Adjust window position and size\n",
    "        win = pygetwindow.getWindowsWithTitle('StepMania')[0]\n",
    "        win.size = (450, 290)\n",
    "        win.moveTo(0, 0)\n",
    "\n",
    "    # One iteration of the environment\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Action dictionary\n",
    "        action_map = {\n",
    "            0:'no_op',\n",
    "            1:'a',\n",
    "            2:'d',\n",
    "            3:'w',\n",
    "            4:'s',\n",
    "        }\n",
    "\n",
    "        # Manage and send input based on action parameter\n",
    "        if action != 0:\n",
    "            if (list(self.cur_held_buttons.values())[action - 1]):\n",
    "                self.cur_held_buttons[list(self.cur_held_buttons)[action - 1]] = False\n",
    "                self.input_sending_helper.releaseKey(action_map[action])\n",
    "            else:\n",
    "                self.cur_held_buttons[list(self.cur_held_buttons)[action - 1]] = True\n",
    "                self.input_sending_helper.holdKey(action_map[action])\n",
    "        \n",
    "        \n",
    "        # Take screenshot for done, observation and reward functions\n",
    "        screenshot = np.array(self.capture.grab(self.window_location))[:,:,:-1].astype(np.uint8)\n",
    "        downscaled_screenshot = self.screenshot_helper.downscaleImage(screenshot, (225, 150), (1, 150, 225))\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Checking if the game is over\n",
    "        done = self.get_over(screenshot)\n",
    "        \n",
    "        # Get the next observation\n",
    "        new_observation = self.get_observation(downscaled_screenshot)\n",
    "        \n",
    "        # Use score as reward\n",
    "        reward = self.get_reward(screenshot)\n",
    "        info = {}\n",
    "\n",
    "        return new_observation, reward, done, info\n",
    "\n",
    "    # Quits result screen and selects new song\n",
    "    def reset(self):\n",
    "        \n",
    "        # Exit to menu, select new song and start\n",
    "        time.sleep(5)\n",
    "        pydirectinput.press('enter')\n",
    "        time.sleep(6)\n",
    "        pydirectinput.press('d')\n",
    "        time.sleep(2)\n",
    "        pydirectinput.press('enter')\n",
    "\n",
    "        # Edge Case - 'Roulette' is selected\n",
    "        time.sleep(1.5)\n",
    "        pydirectinput.press('enter')\n",
    "        time.sleep(3)\n",
    "        pydirectinput.press('enter')\n",
    "\n",
    "        # Reset reward\n",
    "        self.previous_reward = 0\n",
    "        self.steps = 0\n",
    "\n",
    "        # Take screenshot to pass to observation\n",
    "        screenshot = np.array(self.capture.grab(self.window_location))[:,:,:-1].astype(np.uint8)\n",
    "        downscaled_screenshot = self.screenshot_helper.downscaleImage(screenshot, (225, 150), (1, 150, 225))\n",
    "        \n",
    "        return self.get_observation(downscaled_screenshot)\n",
    "\n",
    "    # Returns image of gameplay\n",
    "    def get_observation(self, img):\n",
    "\n",
    "        # Crop gameplay part of the window screenshot\n",
    "        obs = img[:, self.game_location['top']:(self.game_location['top'] + self.game_location['height']), self.game_location['left']:(self.game_location['left'] + self.game_location['width'])]\n",
    "\n",
    "        return obs\n",
    "\n",
    "    # Returns the current score as a reward\n",
    "    def get_reward(self, img):\n",
    "\n",
    "        # Crop score part of the window screenshot\n",
    "        obs = img[self.score_location['top']:(self.score_location['top'] + self.score_location['height']), self.score_location['left']:(self.score_location['left'] + self.score_location['width'])]\n",
    "        \n",
    "        # Calculate the reward by subtracting the previous score from the current score\n",
    "        # If the song is over, or the score isn't recognized properly, set reward to 0 to avoid accidently returning a negative reward\n",
    "        new_reward = self.pattern_recog_helper.analyze_score(obs)\n",
    "        if (new_reward > self.previous_reward):\n",
    "            reward = new_reward - self.previous_reward\n",
    "            # Set the current reward as the previous reward for the next iteration\n",
    "            self.previous_reward = new_reward\n",
    "        else:\n",
    "            reward = 0\n",
    "        return reward\n",
    "\n",
    "    # Checks if the game is over\n",
    "    def get_over(self, img):\n",
    "\n",
    "        # Crop done part of the window screenshot\n",
    "        obs = img[self.done_location['top']:(self.done_location['top'] + self.done_location['height']), self.done_location['left']:(self.done_location['left'] + self.done_location['width'])]\n",
    "        \n",
    "        return self.pattern_recog_helper.analyze_results(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StepManiaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Environment started - Using random inputs')\n",
    "time.sleep(2)\n",
    "for episode in range(10):\n",
    "  done = False\n",
    "  start = time.perf_counter()\n",
    "  while not done:\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "  stop = time.perf_counter()\n",
    "  final_time = stop - start\n",
    "  print(f'Total Reward for episode {episode} is {env.previous_reward}')\n",
    "  print(f'Total steps during this episode: {env.steps}')\n",
    "  print(f'Total duration of this episode is {final_time:0.4f} seconds')\n",
    "  print(f'This equals an average of {env.steps / final_time} images per second')\n",
    "  env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the environment is valid\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback function, that is called after every step\n",
    "# This is used to save the model in regular intervals\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "  def __init__(self, checking_freq, save_path, verbose=1):\n",
    "    super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "    self.checking_freq = checking_freq\n",
    "    self.save_path = save_path\n",
    "\n",
    "  def _init_callback(self):\n",
    "    if self.save_path is not None:\n",
    "      os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "  def _on_step(self):\n",
    "    if (self.num_timesteps % 500 == 0):\n",
    "      self.logger.dump(self.num_timesteps)\n",
    "    if self.n_calls % self.checking_freq == 0:\n",
    "      model_path = os.path.join(self.save_path, f'best_model_{self.n_calls}')\n",
    "      self.model.save(model_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './training/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(checking_freq=1_000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StepManiaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap environment to monitor performance and training process\n",
    "env = gym.make(\"StepManiaEnv-v1\")\n",
    "env = Monitor(env, filename=\"./logs/stepmania-env-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mcapture\u001b[39m.\u001b[39mgrab(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_location))[:,:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m      2\u001b[0m ss_ds \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mget_observation(ss)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mimshow(ss_ds[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "ss = np.array(env.capture.grab(env.window_location))[:,:,:-1].astype(np.uint8)\n",
    "ss_ds = env.get_observation(ss)\n",
    "plt.imshow(ss_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN(\n",
    "  'CnnPolicy',              \n",
    "  env,                      # Used environment\n",
    "  tensorboard_log=LOG_DIR,  # Log directory\n",
    "  verbose=1,                # Enables logging\n",
    "  learning_rate=0.0005,     # Learning rate of the optimizer used in training\n",
    "  buffer_size=120_000,      # Buffer size depending on amount of ram\n",
    "  learning_starts=1_000,    # Learning starts after 1000 steps\n",
    "  # device='cpu'              # Training on cpu or gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "model.learn(total_timesteps=20_000, callback=callback, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x2428effd3a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load past model \n",
    "model.load(r'training\\best_model_10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment started - Using Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m      8\u001b[0m   action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[1;32m----> 9\u001b[0m   obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(\u001b[39mint\u001b[39;49m(action))\n\u001b[0;32m     10\u001b[0m   final_reward \u001b[39m=\u001b[39m reward\n\u001b[0;32m     12\u001b[0m stop \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:95\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[0;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\wrappers\\time_limit.py:18\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     15\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\envs\\classic_control\\stepmania5env.py:75\u001b[0m, in \u001b[0;36mStepManiaEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_sending_helper\u001b[39m.\u001b[39mholdKey(action_map[action])\n\u001b[0;32m     74\u001b[0m \u001b[39m# Take screenshot for done, observation and reward functions\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m screenshot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcapture\u001b[39m.\u001b[39;49mgrab(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow_location))[:,:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     76\u001b[0m downscaled_screenshot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreenshot_helper\u001b[39m.\u001b[39mdownscaleImage(screenshot, (\u001b[39m225\u001b[39m, \u001b[39m150\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m150\u001b[39m, \u001b[39m225\u001b[39m))\n\u001b[0;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mss\\base.py:76\u001b[0m, in \u001b[0;36mMSSBase.grab\u001b[1;34m(self, monitor)\u001b[0m\n\u001b[0;32m     68\u001b[0m     monitor \u001b[39m=\u001b[39m {\n\u001b[0;32m     69\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m: monitor[\u001b[39m0\u001b[39m],\n\u001b[0;32m     70\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtop\u001b[39m\u001b[39m\"\u001b[39m: monitor[\u001b[39m1\u001b[39m],\n\u001b[0;32m     71\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m\"\u001b[39m: monitor[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m monitor[\u001b[39m0\u001b[39m],\n\u001b[0;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m\"\u001b[39m: monitor[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m monitor[\u001b[39m1\u001b[39m],\n\u001b[0;32m     73\u001b[0m     }\n\u001b[0;32m     75\u001b[0m \u001b[39mwith\u001b[39;00m lock:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grab_impl(monitor)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mss\\windows.py:267\u001b[0m, in \u001b[0;36mMSS._grab_impl\u001b[1;34m(self, monitor)\u001b[0m\n\u001b[0;32m    264\u001b[0m     MSS\u001b[39m.\u001b[39mbmp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgdi32\u001b[39m.\u001b[39mCreateCompatibleBitmap(srcdc, width, height)\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgdi32\u001b[39m.\u001b[39mSelectObject(memdc, MSS\u001b[39m.\u001b[39mbmp)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgdi32\u001b[39m.\u001b[39;49mBitBlt(\n\u001b[0;32m    268\u001b[0m     memdc,\n\u001b[0;32m    269\u001b[0m     \u001b[39m0\u001b[39;49m,\n\u001b[0;32m    270\u001b[0m     \u001b[39m0\u001b[39;49m,\n\u001b[0;32m    271\u001b[0m     width,\n\u001b[0;32m    272\u001b[0m     height,\n\u001b[0;32m    273\u001b[0m     srcdc,\n\u001b[0;32m    274\u001b[0m     monitor[\u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    275\u001b[0m     monitor[\u001b[39m\"\u001b[39;49m\u001b[39mtop\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    276\u001b[0m     SRCCOPY \u001b[39m|\u001b[39;49m CAPTUREBLT,\n\u001b[0;32m    277\u001b[0m )\n\u001b[0;32m    278\u001b[0m bits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgdi32\u001b[39m.\u001b[39mGetDIBits(\n\u001b[0;32m    279\u001b[0m     memdc, MSS\u001b[39m.\u001b[39mbmp, \u001b[39m0\u001b[39m, height, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bmi, DIB_RGB_COLORS\n\u001b[0;32m    280\u001b[0m )\n\u001b[0;32m    281\u001b[0m \u001b[39mif\u001b[39;00m bits \u001b[39m!=\u001b[39m height:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Environment started - Using Model')\n",
    "for episode in range(10):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  final_reward = 0\n",
    "  start = time.perf_counter()\n",
    "  while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(int(action))\n",
    "    final_reward = reward\n",
    "\n",
    "  stop = time.perf_counter()\n",
    "  final_time = stop - start\n",
    "\n",
    "  print(f'Total Reward for episode {episode} is {env.previous_reward}')\n",
    "  print(f'Total steps during this episode: {env.steps}')\n",
    "  print(f'Total duration of this episode is {final_time:0.4f} seconds')\n",
    "  print(f'This equals an average of {env.steps / final_time} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from stable_baselines3.common import results_plotter\n",
    "\n",
    "results_plotter.plot_results(\n",
    "  [LOG_DIR], 10000, results_plotter.X_TIMESTEPS, \"StepManiaEnv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
