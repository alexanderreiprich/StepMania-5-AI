{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow\n",
    "# %pip install gym\n",
    "# %pip install keras\n",
    "# %pip install keras-rl2\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from matplotlib import pyplot as plt\n",
    "from mss import mss\n",
    "import numpy as np \n",
    "import time\n",
    "import pydirectinput\n",
    "import pygetwindow\n",
    "import cv2\n",
    "import win32gui\n",
    "import pytesseract\n",
    "from image_analysis.take_screenshot import Screenshot\n",
    "from input_sending.input_sending import SendInput \n",
    "from text_recognition.text_recog import RecognizeText \n",
    "from pattern_recognition.pattern_recog import RecognizePattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepManiaEnv(Env):\n",
    "    \n",
    "    # Setup\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(5)\n",
    "\n",
    "        # Observation Array\n",
    "        self.observation_space = Box(\n",
    "            low=0, \n",
    "            high=255, \n",
    "            shape=(1, 170, 100), \n",
    "            dtype=np.uint\n",
    "        )\n",
    "        \n",
    "        # Define extraction parameters for the game\n",
    "        self.screenshot_helper = Screenshot()\n",
    "        self.text_recog_helper = RecognizeText()\n",
    "        self.input_sending_helper = SendInput()\n",
    "        self.capture = mss()\n",
    "        self.screenshots = 0\n",
    "        self.window_location = {'top': 35, 'left': 10, 'width': 410, 'height': 230}\n",
    "        self.game_location = {'top': 0, 'left': 40, 'width': 150, 'height': 225}\n",
    "        self.combo_location = {'top': 215, 'left': 280, 'width': 100, 'height': 25}\n",
    "        self.done_location = {'top': 0, 'left': 0, 'width': 80, 'height':25}\n",
    "        self.cur_held_buttons = {'a': False, 'd': False, 'w': False, 's': False}\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'G:\\Programme\\Tesseract\\tesseract.exe'\n",
    "\n",
    "    # What is called to do something in the game\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Action dictionary\n",
    "        action_map = {\n",
    "            0:'no_op',\n",
    "            1:'a',\n",
    "            2:'d',\n",
    "            3:'w',\n",
    "            4:'s',\n",
    "        }\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Manage and send input based on action parameter\n",
    "        if action != 0:\n",
    "            if (list(self.cur_held_buttons.values())[action - 1]):\n",
    "                self.cur_held_buttons[list(self.cur_held_buttons)[action - 1]] = False\n",
    "                self.input_sending_helper.releaseKey(action_map[action])\n",
    "            else:\n",
    "                self.cur_held_buttons[list(self.cur_held_buttons)[action - 1]] = True\n",
    "                self.input_sending_helper.holdKey(action_map[action])\n",
    "        \n",
    "\n",
    "        # Take screenshot for done, observation and reward functions\n",
    "        screenshot = np.array(self.capture.grab(self.window_location))[:,:,:-1].astype(np.uint8)\n",
    "        channel_screenshot = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)\n",
    "        self.screenshots += 1\n",
    "\n",
    "        # Checking if the game is over\n",
    "        done = self.get_over(channel_screenshot)\n",
    "\n",
    "        # Get the next observation\n",
    "        new_observation = self.get_observation(channel_screenshot)\n",
    "        \n",
    "        # Use score as reward\n",
    "        reward = self.get_reward(channel_screenshot)\n",
    "        info = {}\n",
    "        stop = time.perf_counter()\n",
    "\n",
    "        return new_observation, reward, done, info\n",
    "\n",
    "    # Restart the game\n",
    "    def reset(self):\n",
    "        \n",
    "        # Exit to menu, select new song and start\n",
    "        time.sleep(5)\n",
    "        pydirectinput.press('enter')\n",
    "        time.sleep(5)\n",
    "        pydirectinput.press('d')\n",
    "        time.sleep(2)\n",
    "        pydirectinput.press('enter')\n",
    "\n",
    "        # Take screenshot to pass to observation\n",
    "        screenshot = np.array(self.capture.grab(self.window_location))[:,:,:-1].astype(np.uint8)\n",
    "        channel_screenshot = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        return self.get_observation(channel_screenshot)\n",
    "\n",
    "    # Get the part of observation of the game that we want\n",
    "    def get_observation(self, img):\n",
    "\n",
    "        # Crop gameplay part of the window screenshot\n",
    "        obs = img[self.game_location['top']:(self.game_location['top'] + self.game_location['height']), self.game_location['left']:(self.game_location['left'] + self.game_location['width'])]\n",
    "        self.screenshots += 1\n",
    "\n",
    "        return obs\n",
    "\n",
    "    # Get the current score as a reward\n",
    "    def get_reward(self, img):\n",
    "\n",
    "        # Crop score part of the window screenshot\n",
    "        obs = img[self.combo_location['top']:(self.combo_location['top'] + self.combo_location['height']), self.combo_location['left']:(self.combo_location['left'] + self.combo_location['width'])]\n",
    "        reward = env.text_recog_helper.get_number_from_image(obs)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    # Get if the game is over\n",
    "    def get_over(self, img):\n",
    "\n",
    "        # Crop done part of the window screenshot\n",
    "        obs = img[self.done_location['top']:(self.done_location['top'] + self.done_location['height']), self.done_location['left']:(self.done_location['left'] + self.done_location['width'])]\n",
    "        # Valid done text\n",
    "        done_strings = ['â€˜our Results', 'Your Results']\n",
    "\n",
    "        return self.text_recog_helper.is_text_in_image(obs, done_strings, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StepManiaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss = np.array(env.capture.grab(env.window_location))[:,:,:-1].astype(np.uint8)\n",
    "plt.imshow(ss[env.combo_location['top']:(env.combo_location['top'] + env.combo_location['height']), env.combo_location['left']:(env.combo_location['left'] + env.combo_location['width'])])\n",
    "env.get_reward(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Environment started - Random Inputs')\n",
    "for episode in range(10):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  final_reward = 0\n",
    "  start = time.perf_counter()\n",
    "  while not done:\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    if final_reward < reward:\n",
    "      final_reward = reward\n",
    "\n",
    "  stop = time.perf_counter()\n",
    "  final_time = stop - start\n",
    "  print(f'Total Reward for episode {episode} is {final_reward}')\n",
    "  print(f'Total screenshots for episode {episode} is {env.screenshots}')\n",
    "  print(f'Total duration of episode {episode} is {final_time:0.4f} seconds')\n",
    "  print(f'This equals an average of {env.screenshots / final_time} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the environment is valid\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "  def __init__(self, checking_freq, save_path, verbose=1):\n",
    "    super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "    self.checking_freq = checking_freq\n",
    "    self.save_path = save_path\n",
    "\n",
    "  def _init_callback(self):\n",
    "    if self.save_path is not None:\n",
    "      os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "  def _on_step(self):\n",
    "    if self.n_calls % self.checking_freq == 0:\n",
    "      model_path = os.path.join(self.save_path, f'best_model_{self.n_calls}')\n",
    "      self.model.save(model_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './training/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(checking_freq=1_000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StepManiaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(\n",
    "  'CnnPolicy',              \n",
    "  env,                      # Used environment\n",
    "  tensorboard_log=LOG_DIR,  # Log directory\n",
    "  verbose=1,                # Enables logging\n",
    "  buffer_size=120_000,      # Buffer size depending on amount of ram\n",
    "  learning_starts=1_000,    # Learning starts after 1000 steps\n",
    "  #device='cpu'             # Training on cpu or gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "model.learn(total_timesteps=1_000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load past model \n",
    "# model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Environment started - Using Model')\n",
    "for episode in range(1):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  final_reward = 0\n",
    "  amount_of_screenshots = 0\n",
    "  start = time.perf_counter()\n",
    "  while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(int(action))\n",
    "    if final_reward < reward:\n",
    "      final_reward = reward\n",
    "      \n",
    "  stop = time.perf_counter()\n",
    "  final_time = stop - start\n",
    "  print(f'Total Reward for episode {episode} is {final_reward}')\n",
    "  print(f'Total screenshots for episode {episode} is {amount_of_screenshots}')\n",
    "  print(f'Total duration of episode {episode} is {final_time:0.4f} seconds')\n",
    "  print(f'This equals an average of {amount_of_screenshots / final_time} images per second')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
