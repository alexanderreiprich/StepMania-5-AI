{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow\n",
    "# %pip install gym\n",
    "# %pip install keras\n",
    "# %pip install keras-rl2\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from matplotlib import pyplot as plt\n",
    "from mss import mss\n",
    "import numpy as np \n",
    "import time\n",
    "import pydirectinput\n",
    "import pygetwindow\n",
    "import cv2\n",
    "import win32gui\n",
    "import pytesseract\n",
    "from image_analysis.take_screenshot import Screenshot\n",
    "from input_sending.input_sending import SendInput \n",
    "from text_recognition.text_recog import RecognizeText \n",
    "from pattern_recognition.pattern_recog import RecognizePattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepManiaEnv(Env):\n",
    "    # Setup\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(5)\n",
    "\n",
    "        # Observation Array\n",
    "        self.observation_space = Box(\n",
    "            low=0, \n",
    "            high=255, \n",
    "            shape=(1, 170, 100), \n",
    "            dtype=np.uint\n",
    "        )\n",
    "        \n",
    "        # Define extraction parameters for the game\n",
    "        self.screenshot_helper = Screenshot()\n",
    "        self.text_recog_helper = RecognizeText()\n",
    "        self.input_sending_helper = SendInput()\n",
    "        self.capture = mss()\n",
    "        self.game_location = {'top': 35, 'left': 110, 'width': 290, 'height': 495}\n",
    "        self.combo_location = {'top': 450, 'left': 570, 'width': 285, 'height': 30}\n",
    "        self.done_location = {'top': 40, 'left': 25, 'width': 150, 'height':30}\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'G:\\Programme\\Tesseract\\tesseract.exe'\n",
    "\n",
    "    # What is called to do something in the game\n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        action_map = {\n",
    "            0:'no_op',\n",
    "            1:'a',\n",
    "            2:'d',\n",
    "            3:'w',\n",
    "            4:'s',\n",
    "        }\n",
    "\n",
    "        # TODO: Does this work with held notes?\n",
    "        # TODO: Change action from single input to array with inputs\n",
    "        # for action in actions:\n",
    "        if action != 0:\n",
    "            self.input_sending_helper.tapKey(action_map[action])\n",
    "            #pydirectinput.press(action_map[action])\n",
    "        \n",
    "        # Checking if the game is over\n",
    "        done = self.get_over()\n",
    "        # Get the next observation\n",
    "        new_observation = self.get_observation()\n",
    "        # Use score as reward\n",
    "        reward = self.get_reward()\n",
    "        info = {}\n",
    "\n",
    "        return new_observation, reward, done, info\n",
    "\n",
    "    # Restart the game\n",
    "    def reset(self):\n",
    "        time.sleep(5)\n",
    "        pydirectinput.press('enter')\n",
    "        time.sleep(2)\n",
    "        pydirectinput.press('d')\n",
    "        pydirectinput.press('enter')\n",
    "        return self.get_observation()\n",
    "\n",
    "    # Get the part of observation of the game that we want\n",
    "    def get_observation(self):\n",
    "        # Use Helper class to get screenshot\n",
    "        # stepWindow = pygetwindow.getWindowsWithTitle('StepMania')\n",
    "        # hwnd = stepWindow[0]._hWnd\n",
    "        # bbox = win32gui.GetWindowRect(hwnd)\n",
    "\n",
    "        # Screenshot gameplay and downscale\n",
    "        raw = np.array(self.capture.grab(self.game_location))[:,:,:-1].astype(np.uint8)\n",
    "        channel = self.screenshot_helper.downscaleImage(raw, (100, 170), (1, 170, 100))\n",
    "\n",
    "        return channel\n",
    "\n",
    "    # Get the current score as a reward\n",
    "    def get_reward(self):\n",
    "        # stepWindow = pygetwindow.getWindowsWithTitle('StepMania')\n",
    "        # hwnd = stepWindow[0]._hWnd\n",
    "        # bbox = win32gui.GetWindowRect(hwnd)\n",
    "        \n",
    "        # Screenshot score, downscale image and return number\n",
    "        reward_img = np.array(self.capture.grab(self.combo_location))[:,:,:-1].astype(np.uint8)\n",
    "        channel = self.screenshot_helper.downscaleImage(reward_img, (285, 30), (1, 30, 285))\n",
    "        reward = env.text_recog_helper.get_number_from_image(channel[0])\n",
    "        return reward\n",
    "\n",
    "    # Get if the game is over\n",
    "    def get_over(self):\n",
    "        # Use Helper class to get screenshot\n",
    "        # stepWindow = pygetwindow.getWindowsWithTitle('StepMania')\n",
    "        # hwnd = stepWindow[0]._hWnd\n",
    "        # bbox = win32gui.GetWindowRect(hwnd)\n",
    "\n",
    "        # Screenshot top left of screen, check for text and return of strings match\n",
    "        done_capture = np.array(self.capture.grab(self.done_location))[:,:,::-1].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(done_capture, cv2.COLOR_BGR2GRAY)\n",
    "        # Valid done text\n",
    "        done_strings = ['Your Results']\n",
    "        return self.text_recog_helper.is_text_in_image(gray, done_strings, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StepManiaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Environment started - Random Inputs')\n",
    "for episode in range(10):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  final_reward = 0\n",
    "  amount_of_screenshots = 0\n",
    "  start = time.perf_counter()\n",
    "  while not done:\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    amount_of_screenshots += 1\n",
    "    if final_reward < reward:\n",
    "      final_reward = reward\n",
    "\n",
    "  stop = time.perf_counter()\n",
    "  final_time = stop - start\n",
    "  print(f'Total Reward for episode {episode} is {final_reward}')\n",
    "  print(f'Total screenshots for episode {episode} is {amount_of_screenshots}')\n",
    "  print(f'Total duration of episode {episode} is {final_time:0.4f} seconds')\n",
    "  print(f'This equals an average of {amount_of_screenshots / final_time} images per second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the environment is valid\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "  def __init__(self, checking_freq, save_path, verbose=1):\n",
    "    super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "    self.checking_freq = checking_freq\n",
    "    self.save_path = save_path\n",
    "\n",
    "  def _init_callback(self):\n",
    "    if self.save_path is not None:\n",
    "      os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "  def _on_step(self):\n",
    "    if self.n_calls % self.checking_freq == 0:\n",
    "      model_path = os.path.join(self.save_path, f'best_model_{self.n_calls}')\n",
    "      self.model.save(model_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './training/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(checking_freq=1_000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StepManiaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(\n",
    "  'CnnPolicy',              \n",
    "  env,                      # Used environment\n",
    "  tensorboard_log=LOG_DIR,  # Log directory\n",
    "  verbose=1,                # Enables logging\n",
    "  buffer_size=120_000,      # Buffer size depending on amount of ram\n",
    "  learning_starts=1_000,    # Learning starts after 1000 steps\n",
    "  #device='cpu'             # Training on cpu or gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "model.learn(total_timesteps=1_000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load past model \n",
    "# model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Environment started - Using Model')\n",
    "for episode in range(1):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  final_reward = 0\n",
    "  amount_of_screenshots = 0\n",
    "  start = time.perf_counter()\n",
    "  while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(int(action))\n",
    "    if final_reward < reward:\n",
    "      final_reward = reward\n",
    "      \n",
    "  stop = time.perf_counter()\n",
    "  final_time = stop - start\n",
    "  print(f'Total Reward for episode {episode} is {final_reward}')\n",
    "  print(f'Total screenshots for episode {episode} is {amount_of_screenshots}')\n",
    "  print(f'Total duration of episode {episode} is {final_time:0.4f} seconds')\n",
    "  print(f'This equals an average of {amount_of_screenshots / final_time} images per second')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
